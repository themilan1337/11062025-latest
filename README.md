# ğŸš€ Enhanced Task Management System

A comprehensive task management application with AI assistants, background processing, web scraping, and modern authentication.

## âœ¨ Features

### Core Task Management
- âœ… Create, read, update, and delete tasks
- ğŸ” JWT-based authentication and authorization
- ğŸ‘¤ User registration and login system
- ğŸ“… Task deadlines and completion tracking
- ğŸ¨ Modern, responsive web interface

### ğŸ¤– AI Assistants
- **OpenAI Integration**: Advanced task analysis and strategic planning
- **Mistral AI Integration**: Fast, efficient task organization
- **Comparison Mode**: Get responses from both assistants simultaneously
- **Conversation Threading**: Maintain context across chat sessions
- **Real-time Chat Interface**: Interactive chatbot with typing indicators

### âš™ï¸ Background Processing
- **Celery Integration**: Asynchronous task processing
- **Redis Backend**: Fast message broker and result storage
- **Scheduled Tasks**: Automated cleanup and maintenance
- **Task Reminders**: Automated deadline notifications
- **Bulk Processing**: Handle multiple tasks efficiently

### ğŸŒ Web Scraping
- **Automated Data Collection**: Scheduled web scraping tasks
- **News Headlines**: Fetch latest news from various sources
- **Custom Scrapers**: Extensible scraping framework
- **Data Storage**: Structured data storage in PostgreSQL

### ğŸ”§ Technical Features
- **Docker Compose**: Complete containerized deployment
- **PostgreSQL Database**: Robust data persistence
- **Redis Caching**: High-performance caching layer
- **CI/CD Pipeline**: Automated testing and deployment
- **Environment Configuration**: Flexible configuration management

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   FastAPI       â”‚    â”‚   PostgreSQL    â”‚
â”‚   (HTML/JS)     â”‚â—„â”€â”€â–ºâ”‚   Backend       â”‚â—„â”€â”€â–ºâ”‚   Database      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Redis         â”‚â—„â”€â”€â–ºâ”‚   Celery        â”‚    â”‚   AI Services   â”‚
â”‚   (Broker)      â”‚    â”‚   Workers       â”‚â—„â”€â”€â–ºâ”‚   (OpenAI/      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   Mistral)      â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose
- Python 3.11+
- OpenAI API Key (optional)
- Mistral AI API Key (optional)

### 1. Clone the Repository
```bash
git clone <repository-url>
cd task-management-system
```

### 2. Environment Setup
```bash
# Copy environment template
cp .env.example .env

# Edit .env file with your configuration
# Add your API keys for AI assistants
```

### 3. Start with Docker Compose
```bash
# Build and start all services
docker-compose up --build

# Or run in background
docker-compose up -d --build
```

### 4. Access the Application
- **Web Interface**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **Alternative Docs**: http://localhost:8000/redoc

## ğŸ“‹ API Endpoints

### Authentication
- `POST /auth/register` - Register new user
- `POST /auth/login` - User login
- `GET /auth/me` - Get current user info

### Tasks
- `GET /tasks/get_tasks` - List user tasks
- `POST /tasks/create` - Create new task
- `PUT /tasks/{task_id}` - Update task
- `DELETE /tasks/{task_id}` - Delete task
- `PUT /tasks/{task_id}/complete` - Mark task complete
- `PUT /tasks/{task_id}/incomplete` - Mark task incomplete

### AI Assistants
- `POST /assistant/initialize` - Initialize AI assistants
- `POST /assistant/message` - Send message to assistant
- `POST /assistant/compare` - Compare responses from both assistants
- `POST /assistant/thread` - Create new conversation thread
- `GET /assistant/conversation/{assistant_type}/{thread_id}` - Get chat history
- `GET /assistant/status` - Get assistant status

## ğŸ”§ Configuration

### Environment Variables

```bash
# Database
DATABASE_URL=postgresql://user:password@localhost/dbname

# Authentication
SECRET_KEY=your-secret-key
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Redis & Celery
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# AI Services
OPENAI_API_KEY=your-openai-api-key
MISTRAL_API_KEY=your-mistral-api-key

# Web Scraping
SCRAPER_USER_AGENT=TaskManager-Bot/1.0
SCRAPER_DELAY=1
SCRAPER_TIMEOUT=30
```

## ğŸ¤– AI Assistant Usage

### OpenAI Assistant
- **Best for**: Complex analysis, strategic planning, detailed explanations
- **Features**: Code interpretation, file analysis, advanced reasoning
- **Model**: GPT-4 Turbo

### Mistral Assistant
- **Best for**: Quick responses, efficient task organization, concise advice
- **Features**: Fast processing, practical solutions, direct answers
- **Model**: Mistral Large

### Comparison Mode
- Send the same query to both assistants
- Compare different approaches and perspectives
- Get comprehensive insights from multiple AI models

## ğŸ”„ Background Tasks

### Scheduled Tasks
- **Daily Cleanup**: Remove completed tasks older than 30 days
- **News Scraping**: Fetch latest headlines every hour
- **Task Reminders**: Send deadline notifications

### Manual Tasks
- **Bulk Processing**: Handle multiple tasks at once
- **Data Scraping**: On-demand web scraping
- **System Maintenance**: Database optimization

## ğŸŒ Web Scraping

### Supported Sources
- News websites (Hacker News, etc.)
- Custom data sources
- API endpoints
- RSS feeds

### Data Storage
- Scraped data stored in PostgreSQL
- Structured tables for different data types
- Automatic deduplication
- Timestamp tracking

## ğŸ§ª Development

### Local Development Setup
```bash
# Install dependencies
pip install -r requirements.txt

# Set up database
psql -c "CREATE DATABASE taskmanager;"

# Run migrations (automatic on startup)
python -m src.main

# Start Celery worker (separate terminal)
celery -A src.celery_app worker --loglevel=info

# Start Celery beat (separate terminal)
celery -A src.celery_app beat --loglevel=info
```

### Running Tests
```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src

# Run specific test file
pytest tests/test_tasks.py
```

### Code Quality
```bash
# Format code
black src/

# Lint code
flake8 src/

# Type checking
mypy src/
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ assistant/          # AI assistant modules
â”‚   â”‚   â”œâ”€â”€ openai_assistant.py
â”‚   â”‚   â”œâ”€â”€ mistral_assistant.py
â”‚   â”‚   â”œâ”€â”€ assistant_manager.py
â”‚   â”‚   â””â”€â”€ api.py
â”‚   â”œâ”€â”€ tasks/              # Task management
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ crud.py
â”‚   â”‚   â”œâ”€â”€ api.py
â”‚   â”‚   â””â”€â”€ celery_tasks.py
â”‚   â”œâ”€â”€ scraper/            # Web scraping
â”‚   â”‚   â””â”€â”€ tasks.py
â”‚   â”œâ”€â”€ auth.py             # Authentication
â”‚   â”œâ”€â”€ auth_api.py         # Auth endpoints
â”‚   â”œâ”€â”€ config.py           # Configuration
â”‚   â”œâ”€â”€ database.py         # Database setup
â”‚   â”œâ”€â”€ celery_app.py       # Celery configuration
â”‚   â””â”€â”€ main.py             # FastAPI application
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html          # Web interface
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml       # CI/CD pipeline
â”œâ”€â”€ docker-compose.yml      # Docker services
â”œâ”€â”€ Dockerfile              # Container definition
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md              # This file
```

## ğŸ”’ Security

- JWT token-based authentication
- Password hashing with bcrypt
- CORS protection
- Environment variable configuration
- API key security best practices

## ğŸš€ Deployment

### Docker Deployment
```bash
# Production build
docker-compose -f docker-compose.yml up -d

# Scale workers
docker-compose up -d --scale celery-worker=3
```

### Manual Deployment
1. Set up PostgreSQL and Redis
2. Configure environment variables
3. Install Python dependencies
4. Run database migrations
5. Start FastAPI server
6. Start Celery workers and beat

## ğŸ“Š Monitoring

- **Health Checks**: Built-in health endpoints
- **Logging**: Comprehensive application logging
- **Metrics**: Task completion and performance metrics
- **Error Tracking**: Detailed error reporting

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For support and questions:
- Create an issue on GitHub
- Check the documentation
- Review the API docs at `/docs`

## ğŸ”® Future Enhancements

- [ ] Mobile app development
- [ ] Advanced analytics dashboard
- [ ] Team collaboration features
- [ ] Integration with external calendars
- [ ] Voice assistant integration
- [ ] Advanced AI task automation
- [ ] Real-time notifications
- [ ] Task templates and workflows
